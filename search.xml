<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>kubectl命令表</title>
    <url>/2022/05/28/kubectl%E5%91%BD%E4%BB%A4%E8%A1%A8/</url>
    <content><![CDATA[<h2 id="kubectl-label"><a href="#kubectl-label" class="headerlink" title="kubectl label"></a><code>kubectl label</code></h2><span id="more"></span>

<p>更新（增加、修改或删除）资源上的 label（标签）。</p>
<ul>
<li>label 必须以字母或数字开头，可以使用字母、数字、连字符、点和下划线，最长63个字符。</li>
<li>如果–overwrite 为 true，则可以覆盖已有的 label，否则尝试覆盖 label 将会报错。</li>
<li>如果指定了–resource-version，则更新将使用此资源版本，否则将使用现有的资源版本。</li>
</ul>
<p>语法</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">label [--overwrite] (-f FILENAME | TYPE NAME) KEY_1=VAL_1 ... KEY_N=VAL_N [--resource-version=version]</span><br></pre></td></tr></table></figure>

<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>给名为foo的Pod添加label unhealthy&#x3D;true。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl label pods foo unhealthy=true</span><br></pre></td></tr></table></figure>

<p>给名为foo的Pod修改label 为 ‘status’ &#x2F; value ‘unhealthy’，且覆盖现有的value。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl label --overwrite pods foo status=unhealthy</span><br></pre></td></tr></table></figure>

<p>给 namespace 中的所有 pod 添加 label</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl label pods --all status=unhealthy</span><br></pre></td></tr></table></figure>

<p>仅当resource-version&#x3D;1时才更新 名为foo的Pod上的label。</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl label pods foo status=unhealthy --resource-version=1</span><br></pre></td></tr></table></figure>

<p>删除名为“bar”的label 。（使用“ - ”减号相连）</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl label pods foo bar-</span><br></pre></td></tr></table></figure>]]></content>
  </entry>
  <entry>
    <title>kubernetes操作</title>
    <url>/2022/06/07/kubernetes%E6%93%8D%E4%BD%9C/</url>
    <content><![CDATA[<span id="more"></span>

<h3 id="授予用户权限"><a href="#授予用户权限" class="headerlink" title="授予用户权限"></a>授予用户权限</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">echo &quot;export KUBECONFIG=/etc/kubernetes/admin.conf&quot; &gt;&gt; ~/.bash_profile</span><br><span class="line">source ~/.bash_profile</span><br></pre></td></tr></table></figure>

<h3 id="登录pod里面容器"><a href="#登录pod里面容器" class="headerlink" title="登录pod里面容器"></a>登录pod里面容器</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl exec $pod -n $namespace -c $container -i -t -- bash：进入指定pod的指定容器（查看pod内有哪些容器的命令：kubectl get pods $pod -n $namespace -o jsonpath=&#123;.spec.containers[*].name&#125;）</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>kubernetes操作</title>
    <url>/2022/06/08/kubernetes%E6%93%8D%E4%BD%9C-1/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title></title>
    <url>/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/</url>
    <content><![CDATA[<h2 id="调度器介绍"><a href="#调度器介绍" class="headerlink" title="调度器介绍"></a>调度器介绍</h2><blockquote>
<p>调度器通过 <code>kubernetes</code> 的 <code>watch</code> 机制来发现集群中新创建且尚未被调度到 <code>Node</code> 上的 <code>Pod</code>。调度器会将发现的每一个未调度的 <code>Pod</code> 调度到一个合适的 <code>Node</code> 上来运行。</p>
<p><code>kube-scheduler</code> 是 <code>Kubernetes</code> 集群的默认调度器，并且是集群控制面的一部分。</p>
<p>在做调度决定时需要考虑的因素包括：单独和整体的资源请求、硬件&#x2F;软件&#x2F;策略限 制、亲和以及反亲和要求、数据局域性、负载间的干扰等等。</p>
</blockquote>
<span id="more"></span>

<h3 id="节点标签"><a href="#节点标签" class="headerlink" title="节点标签"></a>节点标签</h3><p>查看现有node及label</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl get node --show-labels</span><br></pre></td></tr></table></figure>

<p>添加label</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;=&lt;label-value&gt;</span><br></pre></td></tr></table></figure>

<p>删除label</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl label nodes &lt;node-name&gt; &lt;label-key&gt;-</span><br></pre></td></tr></table></figure>



<h3 id="nodeName"><a href="#nodeName" class="headerlink" title="nodeName"></a><code>nodeName</code></h3><p><code>nodeName</code> 是节点选择约束的最简单方法，但一般不推荐。如果 <code>nodeName</code> 在 <code>PodSpec</code> 中指定了，则它优先于其他的节点选择方法。</p>
<p>使用 <code>nodeName</code> 来选择节点的一些限制：<br>• 如果指定的节点不存在。<br>• 如果指定的节点没有资源来容纳 pod，则pod 调度失败。<br>• 云环境中的节点名称并非总是可预测或稳定的。<br><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525172114834.png" alt="image-20220525172114834"></p>
<p>指定的节点没有资源来容纳pod，则pod调度失败</p>
<h3 id="nodeSelector"><a href="#nodeSelector" class="headerlink" title="nodeSelector"></a><code>nodeSelector</code></h3><h4 id="通过标签选择节点"><a href="#通过标签选择节点" class="headerlink" title="通过标签选择节点"></a>通过标签选择节点</h4><p><code>nodeSelector</code> 是节点选择约束的最简单推荐形式。<br>给选择的节点添加标签： </p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl label nodes server2 disktype=ssd</span><br></pre></td></tr></table></figure>

<p><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525172541122.png" alt="image-20220525172541122"></p>
<p>如果没有标签会无法运行（pending）</p>
<h4 id="亲和与反亲和"><a href="#亲和与反亲和" class="headerlink" title="亲和与反亲和"></a>亲和与反亲和</h4><p><code>nodeSelector</code> 提供了一种非常简单的方法来将 pod 约束到具有特定标签的节点上。亲和&#x2F;反亲和功能极大地扩展了你可以表达约束的类型。 可以发现规则是“软”&#x2F;“偏好”，而不是硬性要求，因此，如果调度器无 法满足该要求，仍然调度该 <code>pod</code><br>你可以使用节点上的 <code>pod</code> 的标签来约束，而不是使用节点本身的标签，来允许哪些 <code>pod</code> 可以或者不可以被放置在一起。</p>
<h5 id="1、节点亲和"><a href="#1、节点亲和" class="headerlink" title="1、节点亲和"></a>1、节点亲和</h5><p>• <code>requiredDuringSchedulingIgnoredDuringExecution</code> 必须满足<br>• <code>preferredDuringSchedulingIgnoredDuringExecution</code> 倾向满足<br>• <code>IgnoreDuringExecution</code> 表示如果在Pod运行期间Node的标签发生变化，导致 亲和性策略不能满足，则继续运行当前的Pod。</p>
<p><code>nodeaffinity</code>还支持多种规则匹配条件的配置：<br>• In：label 的值在列表内<br>• NotIn：label 的值不在列表内<br>• Gt：label 的值大于设置的值，不支持Pod亲和性<br>• Lt：label 的值小于设置的值，不支持pod亲和性<br>• Exists：设置的label 存在<br>• DoesNotExist：设置的 label 不存在</p>
<p><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525173028476.png" alt="image-20220525173028476"></p>
<h5 id="2、pod-亲和性和反亲和性"><a href="#2、pod-亲和性和反亲和性" class="headerlink" title="2、pod 亲和性和反亲和性"></a>2、pod 亲和性和反亲和性</h5><p><code>pod</code> 亲和性和反亲和性<br>• <code>podAffinity</code> 主要解决POD可以和哪些POD部署在同一个拓扑域中的问题 （拓扑域用主机标签实现，可以是单个主机，也可以是多个主机组成的 cluster、zone等。）<br>• <code>podAntiAffinity</code>主要解决POD不能和哪些POD部署在同一个拓扑域中的问题。 它们处理的是Kubernetes集群内部POD和POD之间的关系。<br>• Pod 间亲和与反亲和在与更高级别的集合（例如 ReplicaSets，StatefulSets， Deployments 等）一起使用时，它们可能更加有用。可以轻松配置一组应位于相同定义拓扑（例如，节点）中的工作负载。</p>
<p><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525173214167.png" alt="image-20220525173214167"></p>
<p><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525173237352.png" alt="image-20220525173237352"></p>
<h5 id="3、节点亲和性"><a href="#3、节点亲和性" class="headerlink" title="3、节点亲和性"></a>3、节点亲和性</h5><p>NodeAffinity节点亲和性，是Pod上定义的一种属性，使Pod能够按我们的要求调度到某个Node上，而Taints则恰恰相反，它可以让Node拒绝运行Pod，甚至驱逐Pod。</p>
<p>• Taints(污点)是Node的一个属性，设置了Taints后，所以Kubernetes是不会将Pod调度到这个Node上的，于是Kubernetes就给Pod设置了个属性Tolerations(容忍)，只要 Pod能够容忍Node上的污点，那么Kubernetes就会忽略Node上的污点，就能够(不是必须)把Pod调度过去。<br>• 可以使用命令 kubectl taint 给节点增加一个 taint：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">kubectl taint nodes node1 key=value:NoSchedule //创建</span><br><span class="line">kubectl describe nodes server1 |grep Taints //查询</span><br><span class="line">kubectl taint nodes node1 key:NoSchedule- //删除</span><br></pre></td></tr></table></figure>

<p>其中[effect] 可取值： [ NoSchedule | PreferNoSchedule | NoExecute ]<br>• NoSchedule：POD 不会被调度到标记为 taints 节点。<br>• PreferNoSchedule：NoSchedule 的软策略版本。<br>• NoExecute：该选项意味着一旦 Taint 生效，如该节点内正在运行的 POD 没有对应 Tolerate 设置，会直接被逐出。</p>
<h6 id="4-1、污点的查询与删除"><a href="#4-1、污点的查询与删除" class="headerlink" title="4.1、污点的查询与删除"></a>4.1、污点的查询与删除</h6><p><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525173608377.png" alt="image-20220525173608377"></p>
<p><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525173627596.png" alt="image-20220525173627596"></p>
<h6 id="4-2、污点的添加与容忍"><a href="#4-2、污点的添加与容忍" class="headerlink" title="4.2、污点的添加与容忍"></a>4.2、污点的添加与容忍</h6><p><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525173707203.png" alt="image-20220525173707203"></p>
<p>tolerations中定义的key、value、effect，要与node上设置的taint保持一直：<br>• 如果 operator 是 Exists ，value可以省略。<br>• 如果 operator 是 Equal ，则key与value之间的关系必须相等。<br>• 如果不指定operator属性，则默认值为Equal。</p>
<p>还有两个特殊值：<br>• 当不指定key，再配合Exists 就能匹配所有的key与value ，可以容忍所有污点。<br>• 当不指定effect ，则匹配所有的effect。</p>
<p>在PodSpec中为容器设定容忍标签：</p>
<p><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525173941245.png" alt="image-20220525173941245"></p>
<p><img src="/2022/05/25/kubernetes%E8%B0%83%E5%BA%A6/image-20220525174011529.png" alt="image-20220525174011529"></p>
]]></content>
  </entry>
  <entry>
    <title>kubernetes资源</title>
    <url>/2022/06/06/kubernetes%E8%B5%84%E6%BA%90/</url>
    <content><![CDATA[<p><a href="https://jimmysong.io/kubernetes-handbook/practice/node-installation.html">https://jimmysong.io/kubernetes-handbook/practice/node-installation.html</a></p>
<p><a href="https://github.com/huweihuang/kubernetes-notes">huweihuang&#x2F;kubernetes-notes: Kubernetes 学习笔记-https://www.huweihuang.com/kubernetes-notes/ (github.com)</a></p>
]]></content>
  </entry>
  <entry>
    <title>KubeVirt</title>
    <url>/2022/10/14/KubeVirt/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>iptables</title>
    <url>/2022/10/20/iptables/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>kubernetes笔记</title>
    <url>/2022/08/22/kubernetes%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="kubernetes三种IP"><a href="#kubernetes三种IP" class="headerlink" title="kubernetes三种IP"></a>kubernetes三种IP</h2><ul>
<li><p>Node IP：Node节点的IP地址，即物理网卡的IP地址。</p>
<blockquote>
<p>可以是物理机的IP（也可能是虚拟机IP）。每个Service都会在Node节点上开通一个端口，外部可以通过NodeIP:NodePort即可访问Service里的Pod,和我们访问服务器部署的项目一样，IP:端口&#x2F;项目名</p>
</blockquote>
</li>
<li><p>Pod IP：Pod的IP地址，即docker容器的IP地址，此为虚拟IP地址。</p>
<blockquote>
<p>Pod IP是每个Pod的IP地址，他是Docker Engine根据docker网桥的IP地址段进行分配的，通常是一个虚拟的二层网络</p>
<p>同Service下的pod可以直接根据PodIP相互通信<br>不同Service下的pod在集群间pod通信要借助于 cluster ip<br>pod和集群外通信，要借助于node ip</p>
</blockquote>
</li>
<li><p>Cluster IP：Service的IP地址，此为虚拟IP地址。</p>
<blockquote>
<p>Service的IP地址，此为虚拟IP地址。外部网络无法ping通，只有kubernetes集群内部访问使用。</p>
</blockquote>
</li>
</ul>
<h4 id="查看集群节点开放端口"><a href="#查看集群节点开放端口" class="headerlink" title="查看集群节点开放端口"></a>查看集群节点开放端口</h4><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ss -tnl    查看k8s-node1，k8s-node2没有创建pod的时候的开放的端口</span><br></pre></td></tr></table></figure>

<h4 id="service"><a href="#service" class="headerlink" title="service"></a>service</h4><p>port<br>K8s集群内部服务访问service的入口。是service暴露在Cluster上的端口，ClusterIP:Port。如下面的yaml配置文件所示，K8s集群内部节点可以通过30080端口访问Nginx服务，然而外部网络还是不能够访问到服务，因为nodePort参数没有配置。</p>
<p>targetPort</p>
<p>容器的端口，也是最终底层的服务所提供的端口，所以说targetPod也就是Pod的端口。从port或者是nodePort进入的流量，经过路由转发之后，最终都会都通过targetPort进入到Pod中。</p>
<p><font color="red">先查看svc</font></p>
]]></content>
  </entry>
</search>
